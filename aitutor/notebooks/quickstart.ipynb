{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: Your First Neural Network\n",
    "\n",
    "**Course:** AI Skills Hub  \n",
    "**Lesson:** Quick Start Tutorial  \n",
    "**Platform:** AI Skills Hub  \n",
    "**License:** MIT  \n",
    "**GPU Required:** Optional (will run on CPU)  \n",
    "**Estimated Runtime:** 5-10 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this quick start tutorial, you'll:\n",
    "- Build a simple neural network in PyTorch\n",
    "- Understand the basic components of a neural network\n",
    "- Train a model on the MNIST dataset\n",
    "- Make predictions on handwritten digits\n",
    "\n",
    "No prior deep learning experience required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies\n",
    "\n",
    "First, let's make sure we have all the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install torch torchvision matplotlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the MNIST Dataset\n",
    "\n",
    "MNIST is a dataset of 70,000 handwritten digits (0-9). It's perfect for learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Download and load training data\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize Some Examples\n",
    "\n",
    "Let's look at what our data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "examples = iter(train_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "\n",
    "# Plot the first 6 examples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(example_data[i].squeeze(), cmap='gray')\n",
    "    ax.set_title(f\"Label: {example_targets[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define the Neural Network\n",
    "\n",
    "Here's where the magic happens! We'll create a simple 3-layer neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Input layer: 28x28 = 784 pixels\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        # Output layer: 10 classes (digits 0-9)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten the image\n",
    "        x = x.view(-1, 784)\n",
    "        # Pass through layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = SimpleNN()\n",
    "print(model)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define Loss Function and Optimizer\n",
    "\n",
    "These help the model learn from its mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: CrossEntropyLoss for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer: Adam (a popular choice)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Loss function and optimizer ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train the Model\n",
    "\n",
    "Now let's train our neural network! We'll train for just 3 epochs to keep it quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        # Print progress every 100 batches\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch}: [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    print(f'\\nEpoch {epoch} Summary: Avg Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\\n')\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Train for 3 epochs\n",
    "num_epochs = 3\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss, acc = train(model, device, train_loader, optimizer, criterion, epoch)\n",
    "    train_losses.append(loss)\n",
    "    train_accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate on Test Set\n",
    "\n",
    "Let's see how well our model performs on unseen data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    print(f'Test Set: Average loss: {test_loss:.4f}, '\n",
    "          f'Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\\n')\n",
    "    return test_loss, accuracy\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_accuracy = test(model, device, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Make Predictions\n",
    "\n",
    "Let's see our model in action on some test examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some test examples\n",
    "examples = iter(test_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(example_data.to(device))\n",
    "    predictions = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(example_data[i].squeeze(), cmap='gray')\n",
    "    pred = predictions[i].item()\n",
    "    true = example_targets[i].item()\n",
    "    color = 'green' if pred == true else 'red'\n",
    "    ax.set_title(f\"Pred: {pred}, True: {true}\", color=color, fontsize=14, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Green = Correct Prediction, Red = Wrong Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You've just built, trained, and tested your first neural network! Here's what you learned:\n",
    "\n",
    "1. **Loading data** with PyTorch datasets and DataLoaders\n",
    "2. **Building a neural network** with Linear layers and ReLU activation\n",
    "3. **Training** using forward pass, loss calculation, and backpropagation\n",
    "4. **Evaluation** on a test set\n",
    "5. **Making predictions** on new data\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Ready to learn more? Check out:\n",
    "\n",
    "- **[Foundation Track](https://rajgupt.github.io/ai-for-builders/courses/foundation/)** - Deep dive into Python, Math, and ML fundamentals\n",
    "- **[Core Track](https://rajgupt.github.io/ai-for-builders/courses/core/)** - Learn CNNs, RNNs, and advanced architectures\n",
    "- **[Projects](https://rajgupt.github.io/ai-for-builders/projects/)** - Build portfolio-worthy AI projects\n",
    "\n",
    "## Try These Challenges\n",
    "\n",
    "1. **Add more layers:** Modify the network to have 3 or 4 layers\n",
    "2. **Change activation:** Try different activation functions (Tanh, Sigmoid)\n",
    "3. **Tune hyperparameters:** Experiment with learning rate, batch size, epochs\n",
    "4. **Add dropout:** Prevent overfitting with dropout layers\n",
    "5. **Use CNNs:** Replace linear layers with convolutional layers\n",
    "\n",
    "---\n",
    "\n",
    "**Questions?** Join our [community discussions](https://github.com/rajgupt/ai-for-builders/discussions)\n",
    "\n",
    "**Found this helpful?** Star our [GitHub repository](https://github.com/rajgupt/ai-for-builders)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

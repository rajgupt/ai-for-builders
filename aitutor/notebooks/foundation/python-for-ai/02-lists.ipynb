{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Skills Hub - Python for AI\n",
    "## Lesson 2: Lists and Indexing\n",
    "\n",
    "**Learn:** Lists, indexing, slicing, and list comprehensions  \n",
    "**Build:** Data splitting, batch processing, and filtering  \n",
    "**Runtime:** ~30 minutes  \n",
    "**GPU Required:** No  \n",
    "**License:** MIT\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Run this cell first\n",
    "\n",
    "Verify your Python environment is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Platform: {sys.platform}\")\n",
    "print(\"\\n‚úÖ Setup complete! Ready to learn about lists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Creating Lists\n",
    "\n",
    "Lists are ordered collections that store multiple values. Essential for training data, predictions, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list\n",
    "empty_list = []\n",
    "\n",
    "# List of training accuracies over epochs\n",
    "accuracies = [0.82, 0.85, 0.88, 0.91, 0.93]\n",
    "\n",
    "# List of epoch numbers\n",
    "epochs = [1, 2, 3, 4, 5]\n",
    "\n",
    "# List of model names\n",
    "models = [\"ResNet\", \"VGG\", \"MobileNet\"]\n",
    "\n",
    "# Print examples\n",
    "print(f\"Accuracies: {accuracies}\")\n",
    "print(f\"Type: {type(accuracies)}\")\n",
    "print(f\"Length: {len(accuracies)} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Example: Tracking training metrics\n",
    "train_losses = [0.89, 0.76, 0.65, 0.58, 0.52]\n",
    "val_losses = [0.92, 0.81, 0.72, 0.68, 0.65]\n",
    "\n",
    "# Display side by side\n",
    "for epoch, (train_loss, val_loss) in enumerate(zip(train_losses, val_losses), 1):\n",
    "    print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Practice: Create Your Own Lists\n",
    "\n",
    "Create lists to track model predictions and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the following lists:\n",
    "# 1. predictions = [0, 1, 1, 0, 1, 0, 0, 1] (binary predictions)\n",
    "# 2. labels = [0, 1, 0, 0, 1, 0, 1, 1] (ground truth)\n",
    "# 3. learning_rates = [0.1, 0.01, 0.001, 0.0001] (LR schedule)\n",
    "\n",
    "# Your code here:\n",
    "\n",
    "\n",
    "# Test your code\n",
    "print(f\"Predictions: {predictions}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "print(f\"Learning rates: {learning_rates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Indexing - Accessing Elements\n",
    "\n",
    "Lists use zero-based indexing. First element is at index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [0.89, 0.76, 0.65, 0.58, 0.52]\n",
    "\n",
    "# Positive indexing (from start)\n",
    "print(\"Positive indexing:\")\n",
    "print(f\"First loss (index 0): {losses[0]}\")\n",
    "print(f\"Second loss (index 1): {losses[1]}\")\n",
    "print(f\"Last loss (index 4): {losses[4]}\")\n",
    "\n",
    "# Negative indexing (from end)\n",
    "print(\"\\nNegative indexing:\")\n",
    "print(f\"Last loss (index -1): {losses[-1]}\")\n",
    "print(f\"Second to last (index -2): {losses[-2]}\")\n",
    "print(f\"First loss (index -5): {losses[-5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Use Case: Compare initial vs final metrics\n",
    "accuracies = [0.65, 0.72, 0.78, 0.82, 0.85, 0.88]\n",
    "\n",
    "initial_acc = accuracies[0]\n",
    "final_acc = accuracies[-1]\n",
    "improvement = final_acc - initial_acc\n",
    "\n",
    "print(f\"Initial accuracy: {initial_acc:.2%}\")\n",
    "print(f\"Final accuracy: {final_acc:.2%}\")\n",
    "print(f\"Improvement: {improvement:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Practice: Indexing Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions for 10 samples\n",
    "predictions = [0, 1, 1, 0, 1, 0, 0, 1, 1, 0]\n",
    "labels = [0, 1, 0, 0, 1, 0, 1, 1, 1, 0]\n",
    "\n",
    "# TODO: Use indexing to:\n",
    "# 1. Get the first prediction and label\n",
    "# 2. Get the last prediction and label\n",
    "# 3. Check if they match (compare with ==)\n",
    "\n",
    "# Your code here:\n",
    "first_pred = None\n",
    "first_label = None\n",
    "last_pred = None\n",
    "last_label = None\n",
    "\n",
    "first_match = None  # True or False\n",
    "last_match = None   # True or False\n",
    "\n",
    "print(f\"First prediction: {first_pred}, Label: {first_label}, Match: {first_match}\")\n",
    "print(f\"Last prediction: {last_pred}, Label: {last_label}, Match: {last_match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Slicing - Extracting Ranges\n",
    "\n",
    "Slicing allows you to extract portions of a list.  \n",
    "Syntax: `list[start:stop:step]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "print(\"Basic slicing:\")\n",
    "print(f\"First 5: {data[:5]}\")      # [0, 1, 2, 3, 4]\n",
    "print(f\"Last 3: {data[-3:]}\")      # [7, 8, 9]\n",
    "print(f\"Middle (3 to 7): {data[3:7]}\")  # [3, 4, 5, 6]\n",
    "print(f\"Every 2nd element: {data[::2]}\")  # [0, 2, 4, 6, 8]\n",
    "print(f\"Reversed: {data[::-1]}\")   # [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Use Case: Train/Test Split\n",
    "dataset = list(range(100))  # 100 samples\n",
    "\n",
    "# Split 80% train, 20% test\n",
    "split_index = int(0.8 * len(dataset))\n",
    "train_data = dataset[:split_index]\n",
    "test_data = dataset[split_index:]\n",
    "\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "print(f\"Train data (first 10): {train_data[:10]}\")\n",
    "print(f\"Test data (first 10): {test_data[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Use Case: Get recent training history\n",
    "loss_history = [1.5 - (i * 0.01) for i in range(100)]\n",
    "\n",
    "# Get last 10 epochs\n",
    "recent_losses = loss_history[-10:]\n",
    "\n",
    "print(f\"Total epochs: {len(loss_history)}\")\n",
    "print(f\"Last 10 losses: {recent_losses}\")\n",
    "print(f\"Best loss: {min(loss_history):.4f}\")\n",
    "print(f\"Worst loss: {max(loss_history):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Practice: Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with 200 samples\n",
    "full_dataset = list(range(200))\n",
    "\n",
    "# TODO: Split into 60% train, 20% validation, 20% test\n",
    "# Calculate the split indices first\n",
    "# train_end = ?\n",
    "# val_end = ?\n",
    "\n",
    "# Your code here:\n",
    "train_data = None\n",
    "val_data = None\n",
    "test_data = None\n",
    "\n",
    "print(f\"Train samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: List Methods\n",
    "\n",
    "Lists have built-in methods for adding, removing, and modifying elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with empty list\n",
    "losses = []\n",
    "\n",
    "# append() - Add single element\n",
    "losses.append(0.89)\n",
    "losses.append(0.76)\n",
    "print(f\"After append: {losses}\")\n",
    "\n",
    "# extend() - Add multiple elements\n",
    "losses.extend([0.65, 0.58, 0.52])\n",
    "print(f\"After extend: {losses}\")\n",
    "\n",
    "# insert() - Add at specific position\n",
    "losses.insert(0, 1.20)  # Insert at beginning\n",
    "print(f\"After insert: {losses}\")\n",
    "\n",
    "# remove() - Remove first occurrence\n",
    "losses.remove(1.20)\n",
    "print(f\"After remove: {losses}\")\n",
    "\n",
    "# pop() - Remove and return last element\n",
    "last = losses.pop()\n",
    "print(f\"Popped: {last}\")\n",
    "print(f\"After pop: {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Example: Building training history\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Simulate 5 epochs of training\n",
    "for epoch in range(5):\n",
    "    # Simulate decreasing loss\n",
    "    train_loss = 1.0 / (epoch + 1)\n",
    "    val_loss = 1.1 / (epoch + 1)\n",
    "    \n",
    "    # Record metrics\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}: Train={train_loss:.4f}, Val={val_loss:.4f}\")\n",
    "\n",
    "print(f\"\\nFinal training history:\")\n",
    "print(f\"Train losses: {[f'{loss:.4f}' for loss in train_losses]}\")\n",
    "print(f\"Val losses: {[f'{loss:.4f}' for loss in val_losses]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Practice: Managing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with empty predictions list\n",
    "predictions = []\n",
    "\n",
    "# TODO: \n",
    "# 1. Add predictions [0, 1, 1] using append\n",
    "# 2. Add predictions [0, 1] using extend\n",
    "# 3. Remove the last prediction using pop\n",
    "# 4. Print the final predictions list\n",
    "# Expected result: [0, 1, 1, 0]\n",
    "\n",
    "# Your code here:\n",
    "\n",
    "\n",
    "print(f\"Final predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: List Comprehensions\n",
    "\n",
    "List comprehensions provide a concise way to create lists. Essential for data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional way (verbose)\n",
    "squares = []\n",
    "for i in range(10):\n",
    "    squares.append(i ** 2)\n",
    "print(f\"Traditional: {squares}\")\n",
    "\n",
    "# List comprehension (concise)\n",
    "squares = [i ** 2 for i in range(10)]\n",
    "print(f\"Comprehension: {squares}\")\n",
    "\n",
    "# With condition: only even squares\n",
    "even_squares = [i ** 2 for i in range(10) if i % 2 == 0]\n",
    "print(f\"Even squares: {even_squares}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Example: Normalize pixel values\n",
    "pixel_values = [0, 50, 100, 150, 200, 255]\n",
    "\n",
    "# Normalize to [0, 1] range\n",
    "normalized = [pixel / 255.0 for pixel in pixel_values]\n",
    "\n",
    "print(\"Original pixels:\", pixel_values)\n",
    "print(\"Normalized:\", [f\"{val:.3f}\" for val in normalized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Example: Create training batches\n",
    "dataset = list(range(100))\n",
    "batch_size = 16\n",
    "\n",
    "# Create batches using list comprehension\n",
    "batches = [dataset[i:i+batch_size] for i in range(0, len(dataset), batch_size)]\n",
    "\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Number of batches: {len(batches)}\")\n",
    "print(f\"First batch: {batches[0]}\")\n",
    "print(f\"Last batch size: {len(batches[-1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Example: Filter high-confidence predictions\n",
    "predictions = [0, 1, 1, 0, 1, 0, 1, 1]\n",
    "confidences = [0.92, 0.65, 0.88, 0.95, 0.55, 0.78, 0.82, 0.91]\n",
    "\n",
    "# Keep only predictions with confidence > 0.8\n",
    "threshold = 0.8\n",
    "high_conf_preds = [pred for pred, conf in zip(predictions, confidences) if conf > threshold]\n",
    "\n",
    "print(f\"All predictions: {predictions}\")\n",
    "print(f\"Confidences: {confidences}\")\n",
    "print(f\"High confidence (>{threshold}): {high_conf_preds}\")\n",
    "print(f\"Kept {len(high_conf_preds)}/{len(predictions)} predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Practice: List Comprehension Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw loss values (need to be converted to percentages)\n",
    "losses = [0.05, 0.12, 0.08, 0.03, 0.15, 0.02]\n",
    "\n",
    "# TODO: Use list comprehension to:\n",
    "# 1. Convert each loss to percentage (multiply by 100)\n",
    "# 2. Keep only losses that are less than 10%\n",
    "\n",
    "# Your code here:\n",
    "loss_percentages = None  # Convert all to percentages\n",
    "good_losses = None       # Keep only < 10%\n",
    "\n",
    "print(f\"Loss percentages: {loss_percentages}\")\n",
    "print(f\"Good losses (< 10%): {good_losses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Nested Lists (2D Data)\n",
    "\n",
    "Nested lists represent multi-dimensional data like batches of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D list: batch of samples with features\n",
    "# Shape: [batch_size, num_features]\n",
    "batch = [\n",
    "    [0.5, 0.3, 0.8],  # Sample 1\n",
    "    [0.2, 0.9, 0.4],  # Sample 2\n",
    "    [0.7, 0.1, 0.6]   # Sample 3\n",
    "]\n",
    "\n",
    "# Access elements\n",
    "print(\"Batch structure:\")\n",
    "print(f\"Full batch: {batch}\")\n",
    "print(f\"\\nFirst sample: {batch[0]}\")\n",
    "print(f\"Second sample: {batch[1]}\")\n",
    "print(f\"\\nFirst feature of first sample: {batch[0][0]}\")\n",
    "print(f\"Second feature of first sample: {batch[0][1]}\")\n",
    "print(f\"\\nBatch shape: [{len(batch)}, {len(batch[0])}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Example: Process batch of samples\n",
    "batch = [\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0]\n",
    "]\n",
    "\n",
    "# Calculate mean for each sample\n",
    "sample_means = [sum(sample) / len(sample) for sample in batch]\n",
    "\n",
    "print(\"Batch data:\")\n",
    "for i, sample in enumerate(batch):\n",
    "    print(f\"Sample {i + 1}: {sample} -> Mean: {sample_means[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèÜ Final Challenge: Complete Data Pipeline\n",
    "\n",
    "Apply everything you've learned to create a complete data processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset of 100 samples\n",
    "full_dataset = list(range(100))\n",
    "\n",
    "# TODO: Complete the following tasks:\n",
    "# 1. Split into 70% train, 15% val, 15% test\n",
    "# 2. Create batches of size 8 for training data\n",
    "# 3. Print first batch and last batch\n",
    "# 4. Count total batches\n",
    "\n",
    "# Your code here:\n",
    "train_end = None  # Calculate split point\n",
    "val_end = None    # Calculate split point\n",
    "\n",
    "train_data = None\n",
    "val_data = None\n",
    "test_data = None\n",
    "\n",
    "batch_size = 8\n",
    "train_batches = None  # Create batches using list comprehension\n",
    "\n",
    "# Print statistics\n",
    "print(\"Data Split:\")\n",
    "print(f\"Train samples: {len(train_data)}\")\n",
    "print(f\"Val samples: {len(val_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "print(f\"\\nBatch Information:\")\n",
    "print(f\"Number of batches: {len(train_batches)}\")\n",
    "print(f\"First batch: {train_batches[0]}\")\n",
    "print(f\"Last batch: {train_batches[-1]}\")\n",
    "print(f\"Last batch size: {len(train_batches[-1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Quiz: Check Your Understanding\n",
    "\n",
    "Test your knowledge with these quick questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: What does data[3:7] return?\n",
    "data = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "result_1 = data[3:7]\n",
    "print(f\"Q1: {result_1}\")  # Answer: [3, 4, 5, 6]\n",
    "\n",
    "# Question 2: How to get the last element?\n",
    "result_2 = data[-1]\n",
    "print(f\"Q2: {result_2}\")  # Answer: 9\n",
    "\n",
    "# Question 3: What's the difference between append and extend?\n",
    "list1 = [1, 2]\n",
    "list1.append([3, 4])\n",
    "print(f\"Q3a (append): {list1}\")  # [1, 2, [3, 4]]\n",
    "\n",
    "list2 = [1, 2]\n",
    "list2.extend([3, 4])\n",
    "print(f\"Q3b (extend): {list2}\")  # [1, 2, 3, 4]\n",
    "\n",
    "# Question 4: Create 80/20 split\n",
    "dataset = list(range(100))\n",
    "split_idx = int(0.8 * len(dataset))\n",
    "train = dataset[:split_idx]\n",
    "test = dataset[split_idx:]\n",
    "print(f\"Q4: Train={len(train)}, Test={len(test)}\")  # 80, 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed Lesson 2! You now understand:\n",
    "\n",
    "- ‚úÖ Creating and manipulating lists\n",
    "- ‚úÖ Indexing and slicing for data access\n",
    "- ‚úÖ List methods (append, extend, pop, etc.)\n",
    "- ‚úÖ List comprehensions for efficient processing\n",
    "- ‚úÖ Nested lists for batch data\n",
    "- ‚úÖ Train/test splitting and batch creation\n",
    "\n",
    "**Next Steps:**\n",
    "- Complete the [Lesson 2 Quiz](https://rajgupt.github.io/ai-for-builders/courses/foundation/python-for-ai/quizzes/#lesson-2)\n",
    "- Move on to [Lesson 3: Dictionaries and Data Structures](https://rajgupt.github.io/ai-for-builders/courses/foundation/python-for-ai/03-dictionaries/)\n",
    "\n",
    "---\n",
    "\n",
    "**Resources:**\n",
    "- [Python Lists Documentation](https://docs.python.org/3/tutorial/datastructures.html)\n",
    "- [List Comprehensions Guide](https://realpython.com/list-comprehension-python/)\n",
    "- [Data Splitting Best Practices](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "**License:** MIT | **Course:** AI Skills Hub | **Lesson:** 2/7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
